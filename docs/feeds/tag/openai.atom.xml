<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Pedantic Journal - openai</title><link href="https://pedanticjournal.com/" rel="alternate"/><link href="https://pedanticjournal.com/feeds/tag/openai.atom.xml" rel="self"/><id>https://pedanticjournal.com/</id><updated>2025-07-18T00:00:00+01:00</updated><subtitle>Thoughts on AI and other subjects.</subtitle><entry><title>Test</title><link href="https://pedanticjournal.com/testing/" rel="alternate"/><published>2025-07-18T00:00:00+01:00</published><updated>2025-07-18T00:00:00+01:00</updated><author><name>Guy Gregory</name></author><id>tag:pedanticjournal.com,2025-07-18:/testing/</id><content type="html">&lt;p&gt;This is a test&lt;/p&gt;</content><category term="Blog"/><category term="azureai"/><category term="openai"/></entry><entry><title>Responses API on Azure OpenAI</title><link href="https://pedanticjournal.com/responses-api/" rel="alternate"/><published>2025-03-11T00:00:00+00:00</published><updated>2025-03-11T00:00:00+00:00</updated><author><name>Guy Gregory</name></author><id>tag:pedanticjournal.com,2025-03-11:/responses-api/</id><summary type="html">&lt;p&gt;Responses API combines the simplicity of Chat Completions with the tool use and state management of the Assistants API.&lt;/p&gt;</summary><content type="html">&lt;p&gt;The Responses API is a new stateful API from OpenAI. It brings together the best capabilities from the chat completions and assistants API in one unified experience. The Responses API also adds support for the new computer-use-preview model which powers the Computer use capability.&lt;/p&gt;
&lt;p&gt;I've shared some basic code samples on my &lt;a href="https://aka.ms/ResponsesAPI"&gt;GitHub repo&lt;/a&gt; for those who want to get started using Responses API on Azure OpenAI:&lt;/p&gt;
&lt;p&gt;Responses API GitHub repo:&lt;br&gt;
&lt;a href="https://aka.ms/ResponsesAPI"&gt;https://aka.ms/ResponsesAPI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Microsoft Learn Documentation:&lt;br&gt;
&lt;a href="https://aka.ms/ResponsesAPI/Docs"&gt;https://aka.ms/ResponsesAPI/Docs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Announcement blog post:&lt;br&gt;
&lt;a href="https://azure.microsoft.com/blog/announcing-the-responses-api-and-computer-using-agent-in-azure-ai-foundry/"&gt;https://azure.microsoft.com/blog/announcing-the-responses-api-and-computer-using-agent-in-azure-ai-foundry/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Request access to the computer-use-preview model:&lt;br&gt;
&lt;a href="https://aka.ms/oai/cuaaccess"&gt;https://aka.ms/oai/cuaaccess&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Here's a basic example from the &lt;a href="https://aka.ms/ResponsesAPI"&gt;repo&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;openai&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AzureOpenAI&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dotenv&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_dotenv&lt;/span&gt;

&lt;span class="n"&gt;load_dotenv&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AzureOpenAI&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;api_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;AZURE_OPENAI_API_KEY&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;  
    &lt;span class="n"&gt;api_version&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;AZURE_OPENAI_API_VERSION&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="n"&gt;azure_endpoint&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;AZURE_OPENAI_API_ENDPOINT&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;responses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;AZURE_OPENAI_API_MODEL&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
    &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Tell me a joke.&amp;quot;&lt;/span&gt;

&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="Blog"/><category term="azureai"/><category term="openai"/></entry><entry><title>GPT-4o mini available in Azure OpenAI</title><link href="https://pedanticjournal.com/gpt-4o-mini/" rel="alternate"/><published>2024-08-01T00:00:00+01:00</published><updated>2024-08-01T00:00:00+01:00</updated><author><name>Guy Gregory</name></author><id>tag:pedanticjournal.com,2024-08-01:/gpt-4o-mini/</id><summary type="html">&lt;p&gt;Towards intelligence too cheap to meter&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/openai-s-gpt-4o-mini-now-available-in-api-with-vision/ba-p/4200640"&gt;GPT-4o mini can now be deployed in the East US Azure region&lt;/a&gt;, with more regions coming soon. Having been available in preview for the last week via the Early Access Playground, partners and customers can now access GPT-4o mini via the Azure OpenAI API.&lt;/p&gt;
&lt;p&gt;This new, smaller version of OpenAI's GPT-4o model offers speed, capability, vision, 128k context window, all at a fraction of the cost of the standard GPT-4o model - and even cheaper than GPT-3.5 Turbo.&lt;/p&gt;
&lt;p&gt;GPT-4o mini will initially be available in Standard Global, and Standard Regional &lt;a href="https://learn.microsoft.com/azure/ai-services/openai/how-to/deployment-types"&gt;deployment types&lt;/a&gt;, with Batch, and Provisioned coming soon. Standard Global pricing is a staggering $0.15 per 1M tokens for input, and $0.60 per 1M tokens for output.&lt;/p&gt;
&lt;p&gt;Based on my own experience using GPT-4o mini in the Azure OpenAI Playground, and also how strongly it's scoring on independent evaluations, I'm convinced that it's going to quickly become the most popular model in the Azure OpenAI Service.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image" src="https://github.com/user-attachments/assets/e2626dd4-31f4-4e2a-b03c-f859e314c3ea"&gt;&lt;/p&gt;
&lt;p&gt;If you want to try GPT-4o mini yourself, try deploying the model in &lt;a href="https://oai.azure.com/"&gt;Azure OpenAI Studio&lt;/a&gt;, or use one of the many &lt;a href="https://github.com/Azure-Samples/"&gt;code samples on GitHub&lt;/a&gt;. If you've never used the Azure OpenAI Service before, you'll be pleased to know that last month, the signup process was streamlined, removing the need to submit a manual form for access.&lt;/p&gt;</content><category term="Blog"/><category term="azureai"/><category term="openai"/></entry></feed>